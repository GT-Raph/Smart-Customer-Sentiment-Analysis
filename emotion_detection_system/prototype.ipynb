{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "398ed2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install deepface\n",
    "# %pip install opencv-python\n",
    "# %pip install opencv-python-headless\n",
    "# %pip install matplotlib\n",
    "# %pip install tensorflow\n",
    "# %pip install keras\n",
    "# %pip install numpy\n",
    "# %pip install mysql-connector-python\n",
    "# %pip install pandas\n",
    "# %pip install scikit-learn\n",
    "# %pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8632fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from deepface import DeepFace\n",
    "import mysql.connector\n",
    "import os\n",
    "from datetime import datetime\n",
    "from IPython.display import display, Image, clear_output\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a92d9973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Connected to MySQL Database\n"
     ]
    }
   ],
   "source": [
    "# Connect to MySQL (XAMPP must be running)\n",
    "db = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"\",  # Replace with MySQL password if set\n",
    "    database=\"emotion_detection\"\n",
    ")\n",
    "cursor = db.cursor()\n",
    "print(\"✅ Connected to MySQL Database\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "941d2360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔧 Helper Functions\n",
    "\n",
    "def get_user_by_face_id(face_id):\n",
    "    cursor.execute(\"SELECT * FROM users WHERE face_id = %s\", (face_id,))\n",
    "    return cursor.fetchone()\n",
    "\n",
    "def insert_user(face_id, image_path):\n",
    "    cursor.execute(\"INSERT INTO users (face_id, image_path) VALUES (%s, %s)\", (face_id, image_path))\n",
    "    db.commit()\n",
    "    return cursor.lastrowid\n",
    "\n",
    "def log_visit(user_id, emotion):\n",
    "    cursor.execute(\"INSERT INTO visits (user_id, emotion) VALUES (%s, %s)\", (user_id, emotion))\n",
    "    db.commit()\n",
    "\n",
    "def ensure_dir(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8d75fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎬 Webcam Started - Press 'q' in video window to stop\n"
     ]
    }
   ],
   "source": [
    "# 🎥 Start Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "ensure_dir(\"captured_faces\")\n",
    "print(\"🎬 Webcam Started - Press 'q' in video window to stop\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23a5f97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to format and display DeepFace results\n",
    "def display_deepface_results(results):\n",
    "    for result in results:\n",
    "        print(\"DeepFace Results:\")\n",
    "        print(f\"Dominant Emotion: {result.get('dominant_emotion', 'Unknown')}\")\n",
    "        print(f\"Face Confidence: {result.get('face_confidence', 'N/A')}\")\n",
    "        print(\"Region:\")\n",
    "        region = result.get('region', {})\n",
    "        for key, value in region.items():\n",
    "            print(f\"  {key}: {value}\")\n",
    "        print(\"Emotions:\")\n",
    "        emotions = result.get('emotion', {})\n",
    "        for emotion, confidence in emotions.items():\n",
    "            print(f\"  {emotion}: {confidence:.2f}\")\n",
    "        print()  # Add a blank line for readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "469dc9fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepFace Results:\n",
      "Dominant Emotion: neutral\n",
      "Face Confidence: 0.95\n",
      "Region:\n",
      "  x: 328\n",
      "  y: 0\n",
      "  w: 181\n",
      "  h: 181\n",
      "  left_eye: (451, 69)\n",
      "  right_eye: (375, 65)\n",
      "Emotions:\n",
      "  angry: 0.18\n",
      "  disgust: 0.00\n",
      "  fear: 0.17\n",
      "  happy: 0.00\n",
      "  sad: 0.12\n",
      "  surprise: 0.00\n",
      "  neutral: 99.52\n",
      "\n",
      "🚫 Face not detected or error: invalid literal for int() with base 10: 'DESKTOP-UQ9OCE2'\n",
      "DeepFace Results:\n",
      "Dominant Emotion: sad\n",
      "Face Confidence: 0\n",
      "Region:\n",
      "  x: 0\n",
      "  y: 0\n",
      "  w: 639\n",
      "  h: 479\n",
      "  left_eye: None\n",
      "  right_eye: None\n",
      "Emotions:\n",
      "  angry: 0.00\n",
      "  disgust: 0.00\n",
      "  fear: 42.98\n",
      "  happy: 0.00\n",
      "  sad: 56.93\n",
      "  surprise: 0.00\n",
      "  neutral: 0.09\n",
      "\n",
      "🚫 Face not detected or error: invalid literal for int() with base 10: 'DESKTOP-UQ9OCE2'\n",
      "DeepFace Results:\n",
      "Dominant Emotion: neutral\n",
      "Face Confidence: 0.93\n",
      "Region:\n",
      "  x: 312\n",
      "  y: 161\n",
      "  w: 139\n",
      "  h: 139\n",
      "  left_eye: None\n",
      "  right_eye: None\n",
      "Emotions:\n",
      "  angry: 0.02\n",
      "  disgust: 0.00\n",
      "  fear: 0.01\n",
      "  happy: 0.00\n",
      "  sad: 0.10\n",
      "  surprise: 0.00\n",
      "  neutral: 99.87\n",
      "\n",
      "🚫 Face not detected or error: invalid literal for int() with base 10: 'DESKTOP-UQ9OCE2'\n",
      "DeepFace Results:\n",
      "Dominant Emotion: neutral\n",
      "Face Confidence: 0.95\n",
      "Region:\n",
      "  x: 307\n",
      "  y: 159\n",
      "  w: 158\n",
      "  h: 158\n",
      "  left_eye: None\n",
      "  right_eye: None\n",
      "Emotions:\n",
      "  angry: 0.06\n",
      "  disgust: 0.00\n",
      "  fear: 0.01\n",
      "  happy: 0.01\n",
      "  sad: 0.12\n",
      "  surprise: 0.00\n",
      "  neutral: 99.80\n",
      "\n",
      "🚫 Face not detected or error: invalid literal for int() with base 10: 'DESKTOP-UQ9OCE2'\n",
      "DeepFace Results:\n",
      "Dominant Emotion: neutral\n",
      "Face Confidence: 0.93\n",
      "Region:\n",
      "  x: 311\n",
      "  y: 158\n",
      "  w: 151\n",
      "  h: 151\n",
      "  left_eye: None\n",
      "  right_eye: None\n",
      "Emotions:\n",
      "  angry: 0.02\n",
      "  disgust: 0.00\n",
      "  fear: 0.00\n",
      "  happy: 0.00\n",
      "  sad: 0.06\n",
      "  surprise: 0.00\n",
      "  neutral: 99.92\n",
      "\n",
      "🚫 Face not detected or error: invalid literal for int() with base 10: 'DESKTOP-UQ9OCE2'\n",
      "DeepFace Results:\n",
      "Dominant Emotion: neutral\n",
      "Face Confidence: 0.96\n",
      "Region:\n",
      "  x: 268\n",
      "  y: 97\n",
      "  w: 149\n",
      "  h: 149\n",
      "  left_eye: None\n",
      "  right_eye: None\n",
      "Emotions:\n",
      "  angry: 1.55\n",
      "  disgust: 0.00\n",
      "  fear: 0.02\n",
      "  happy: 0.00\n",
      "  sad: 0.57\n",
      "  surprise: 0.00\n",
      "  neutral: 97.85\n",
      "\n",
      "🚫 Face not detected or error: invalid literal for int() with base 10: 'DESKTOP-UQ9OCE2'\n",
      "DeepFace Results:\n",
      "Dominant Emotion: neutral\n",
      "Face Confidence: 0.96\n",
      "Region:\n",
      "  x: 310\n",
      "  y: 82\n",
      "  w: 151\n",
      "  h: 151\n",
      "  left_eye: None\n",
      "  right_eye: None\n",
      "Emotions:\n",
      "  angry: 0.03\n",
      "  disgust: 0.00\n",
      "  fear: 0.01\n",
      "  happy: 0.00\n",
      "  sad: 0.06\n",
      "  surprise: 0.00\n",
      "  neutral: 99.90\n",
      "\n",
      "🚫 Face not detected or error: invalid literal for int() with base 10: 'DESKTOP-UQ9OCE2'\n",
      "DeepFace Results:\n",
      "Dominant Emotion: neutral\n",
      "Face Confidence: 0.96\n",
      "Region:\n",
      "  x: 0\n",
      "  y: 194\n",
      "  w: 270\n",
      "  h: 270\n",
      "  left_eye: None\n",
      "  right_eye: None\n",
      "Emotions:\n",
      "  angry: 0.28\n",
      "  disgust: 0.00\n",
      "  fear: 0.00\n",
      "  happy: 0.00\n",
      "  sad: 0.01\n",
      "  surprise: 0.00\n",
      "  neutral: 99.70\n",
      "\n",
      "🚫 Face not detected or error: invalid literal for int() with base 10: 'DESKTOP-UQ9OCE2'\n",
      "DeepFace Results:\n",
      "Dominant Emotion: neutral\n",
      "Face Confidence: 0.95\n",
      "Region:\n",
      "  x: 273\n",
      "  y: 95\n",
      "  w: 153\n",
      "  h: 153\n",
      "  left_eye: None\n",
      "  right_eye: None\n",
      "Emotions:\n",
      "  angry: 0.00\n",
      "  disgust: 0.00\n",
      "  fear: 0.00\n",
      "  happy: 0.00\n",
      "  sad: 0.01\n",
      "  surprise: 0.00\n",
      "  neutral: 99.99\n",
      "\n",
      "🚫 Face not detected or error: invalid literal for int() with base 10: 'DESKTOP-UQ9OCE2'\n",
      "DeepFace Results:\n",
      "Dominant Emotion: neutral\n",
      "Face Confidence: 0.97\n",
      "Region:\n",
      "  x: 276\n",
      "  y: 98\n",
      "  w: 159\n",
      "  h: 159\n",
      "  left_eye: None\n",
      "  right_eye: None\n",
      "Emotions:\n",
      "  angry: 2.46\n",
      "  disgust: 0.00\n",
      "  fear: 0.23\n",
      "  happy: 0.05\n",
      "  sad: 0.62\n",
      "  surprise: 0.01\n",
      "  neutral: 96.63\n",
      "\n",
      "🚫 Face not detected or error: invalid literal for int() with base 10: 'DESKTOP-UQ9OCE2'\n",
      "DeepFace Results:\n",
      "Dominant Emotion: neutral\n",
      "Face Confidence: 0.95\n",
      "Region:\n",
      "  x: 278\n",
      "  y: 90\n",
      "  w: 163\n",
      "  h: 163\n",
      "  left_eye: None\n",
      "  right_eye: None\n",
      "Emotions:\n",
      "  angry: 0.69\n",
      "  disgust: 0.00\n",
      "  fear: 0.03\n",
      "  happy: 0.00\n",
      "  sad: 0.44\n",
      "  surprise: 0.00\n",
      "  neutral: 98.83\n",
      "\n",
      "🚫 Face not detected or error: invalid literal for int() with base 10: 'DESKTOP-UQ9OCE2'\n",
      "DeepFace Results:\n",
      "Dominant Emotion: neutral\n",
      "Face Confidence: 0.96\n",
      "Region:\n",
      "  x: 279\n",
      "  y: 91\n",
      "  w: 161\n",
      "  h: 161\n",
      "  left_eye: None\n",
      "  right_eye: None\n",
      "Emotions:\n",
      "  angry: 0.12\n",
      "  disgust: 0.00\n",
      "  fear: 0.01\n",
      "  happy: 0.00\n",
      "  sad: 0.09\n",
      "  surprise: 0.00\n",
      "  neutral: 99.78\n",
      "\n",
      "🚫 Face not detected or error: invalid literal for int() with base 10: 'DESKTOP-UQ9OCE2'\n",
      "DeepFace Results:\n",
      "Dominant Emotion: neutral\n",
      "Face Confidence: 0.94\n",
      "Region:\n",
      "  x: 279\n",
      "  y: 89\n",
      "  w: 160\n",
      "  h: 160\n",
      "  left_eye: None\n",
      "  right_eye: None\n",
      "Emotions:\n",
      "  angry: 0.03\n",
      "  disgust: 0.00\n",
      "  fear: 0.03\n",
      "  happy: 0.00\n",
      "  sad: 0.04\n",
      "  surprise: 0.01\n",
      "  neutral: 99.89\n",
      "\n",
      "🚫 Face not detected or error: invalid literal for int() with base 10: 'DESKTOP-UQ9OCE2'\n",
      "DeepFace Results:\n",
      "Dominant Emotion: neutral\n",
      "Face Confidence: 0.94\n",
      "Region:\n",
      "  x: 310\n",
      "  y: 63\n",
      "  w: 166\n",
      "  h: 166\n",
      "  left_eye: None\n",
      "  right_eye: None\n",
      "Emotions:\n",
      "  angry: 0.04\n",
      "  disgust: 0.00\n",
      "  fear: 0.00\n",
      "  happy: 0.01\n",
      "  sad: 0.08\n",
      "  surprise: 0.00\n",
      "  neutral: 99.86\n",
      "\n",
      "🚫 Face not detected or error: invalid literal for int() with base 10: 'DESKTOP-UQ9OCE2'\n",
      "DeepFace Results:\n",
      "Dominant Emotion: neutral\n",
      "Face Confidence: 0.95\n",
      "Region:\n",
      "  x: 295\n",
      "  y: 111\n",
      "  w: 146\n",
      "  h: 146\n",
      "  left_eye: None\n",
      "  right_eye: None\n",
      "Emotions:\n",
      "  angry: 0.03\n",
      "  disgust: 0.00\n",
      "  fear: 0.02\n",
      "  happy: 0.00\n",
      "  sad: 0.16\n",
      "  surprise: 0.00\n",
      "  neutral: 99.80\n",
      "\n",
      "🚫 Face not detected or error: invalid literal for int() with base 10: 'DESKTOP-UQ9OCE2'\n",
      "DeepFace Results:\n",
      "Dominant Emotion: neutral\n",
      "Face Confidence: 0.95\n",
      "Region:\n",
      "  x: 304\n",
      "  y: 79\n",
      "  w: 164\n",
      "  h: 164\n",
      "  left_eye: None\n",
      "  right_eye: None\n",
      "Emotions:\n",
      "  angry: 0.28\n",
      "  disgust: 0.00\n",
      "  fear: 0.18\n",
      "  happy: 0.06\n",
      "  sad: 0.01\n",
      "  surprise: 1.14\n",
      "  neutral: 98.32\n",
      "\n",
      "🚫 Face not detected or error: invalid literal for int() with base 10: 'DESKTOP-UQ9OCE2'\n",
      "DeepFace Results:\n",
      "Dominant Emotion: neutral\n",
      "Face Confidence: 0.94\n",
      "Region:\n",
      "  x: 305\n",
      "  y: 93\n",
      "  w: 143\n",
      "  h: 143\n",
      "  left_eye: (402, 151)\n",
      "  right_eye: (338, 152)\n",
      "Emotions:\n",
      "  angry: 0.00\n",
      "  disgust: 0.00\n",
      "  fear: 0.00\n",
      "  happy: 0.00\n",
      "  sad: 0.00\n",
      "  surprise: 0.00\n",
      "  neutral: 100.00\n",
      "\n",
      "🚫 Face not detected or error: invalid literal for int() with base 10: 'DESKTOP-UQ9OCE2'\n",
      "DeepFace Results:\n",
      "Dominant Emotion: neutral\n",
      "Face Confidence: 0.96\n",
      "Region:\n",
      "  x: 295\n",
      "  y: 92\n",
      "  w: 143\n",
      "  h: 143\n",
      "  left_eye: None\n",
      "  right_eye: None\n",
      "Emotions:\n",
      "  angry: 1.29\n",
      "  disgust: 0.00\n",
      "  fear: 0.23\n",
      "  happy: 0.00\n",
      "  sad: 0.33\n",
      "  surprise: 0.01\n",
      "  neutral: 98.13\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10164\\2249538686.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     75\u001b[0m         cv2.putText(frame, f\"Emotion: {dominant_emotion}\", (50, 100),  # Display Dominant Emotion\n\u001b[0;32m     76\u001b[0m                     cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"🚫 Face not detected or error:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Face Recognition & Emotion Detection\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;36m0xFF\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'q'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Piss Off\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\deepface\\DeepFace.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(img1_path, img2_path, model_name, detector_backend, distance_metric, enforce_detection, align, expand_percentage, normalization, silent, threshold, anti_spoofing)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m         \u001b[1;33m-\u001b[0m \u001b[1;34m'time'\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTime\u001b[0m \u001b[0mtaken\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mverification\u001b[0m \u001b[0mprocess\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mseconds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m     \"\"\"\n\u001b[0;32m    149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m     return verification.verify(\n\u001b[0m\u001b[0;32m    151\u001b[0m         \u001b[0mimg1_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimg1_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m         \u001b[0mimg2_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimg2_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m         \u001b[0mmodel_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Piss Off\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\deepface\\modules\\verification.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(img1_path, img2_path, model_name, detector_backend, distance_metric, enforce_detection, align, expand_percentage, normalization, silent, threshold, anti_spoofing)\u001b[0m\n\u001b[0;32m    177\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Exception while processing img{index}_path\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg_embeddings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_facial_areas\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m     \u001b[0mimg1_embeddings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg1_facial_areas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_embeddings_and_facial_areas\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg1_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    182\u001b[0m     \u001b[0mimg2_embeddings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg2_facial_areas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_embeddings_and_facial_areas\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg2_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m     \u001b[0mmin_distance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_idy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"inf\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Piss Off\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\deepface\\modules\\verification.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(img_path, index)\u001b[0m\n\u001b[0;32m    174\u001b[0m                     \u001b[0mnormalization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnormalization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m                     \u001b[0manti_spoofing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0manti_spoofing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m                 )\n\u001b[0;32m    177\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Exception while processing img{index}_path\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg_embeddings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_facial_areas\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Piss Off\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\deepface\\modules\\verification.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(img_path, model_name, detector_backend, enforce_detection, align, expand_percentage, normalization, anti_spoofing)\u001b[0m\n\u001b[0;32m    244\u001b[0m     \u001b[1;31m# find embeddings for each face\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    245\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mimg_obj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mimg_objs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0manti_spoofing\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mTrue\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mimg_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"is_real\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Spoof detected in given image.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 248\u001b[1;33m         img_embedding_obj = representation.represent(\n\u001b[0m\u001b[0;32m    249\u001b[0m             \u001b[0mimg_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimg_obj\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"face\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m             \u001b[0mmodel_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m             \u001b[0menforce_detection\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0menforce_detection\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Piss Off\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\deepface\\modules\\representation.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(img_path, model_name, enforce_detection, detector_backend, align, expand_percentage, normalization, anti_spoofing, max_faces)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# custom normalization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormalization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnormalization\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m         \u001b[0membedding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m         resp_objs.append(\n\u001b[0;32m    136\u001b[0m             {\n",
      "\u001b[1;32mc:\\Users\\Piss Off\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\deepface\\models\\facial_recognition\\VGGFace.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;31m# embedding = model.predict(img, verbose=0)[0].tolist()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;31m# having normalization layer in descriptor troubles for some gpu users (e.g. issue 957, 966)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[1;31m# instead we are now calculating it with traditional way not with keras backend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m         \u001b[0membedding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m         \u001b[0membedding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mverification\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ml2_normalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0membedding\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Piss Off\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tf_keras\\src\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Piss Off\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tf_keras\\src\\engine\\training.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    584\u001b[0m                 \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mcopied_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcopied_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    586\u001b[0m             \u001b[0mlayout_map_lib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_map_subclass_model_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_layout_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 588\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Piss Off\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tf_keras\\src\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Piss Off\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tf_keras\\src\\engine\\base_layer.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1149\u001b[0m                     )\n\u001b[0;32m   1150\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_saved_model_inputs_spec\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_save_spec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1153\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Piss Off\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tf_keras\\src\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    154\u001b[0m                 \u001b[0mnew_e\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mnew_e\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0msignature\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m             \u001b[1;32mdel\u001b[0m \u001b[0mbound_signature\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Piss Off\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tf_keras\\src\\engine\\functional.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    510\u001b[0m         \u001b[0mReturns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    511\u001b[0m             \u001b[0mA\u001b[0m \u001b[0mtensor\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mthere\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0msingle\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    512\u001b[0m             \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtensors\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mthere\u001b[0m \u001b[0mare\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mthan\u001b[0m \u001b[0mone\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m         \"\"\"\n\u001b[1;32m--> 514\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_internal_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Piss Off\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tf_keras\\src\\engine\\functional.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    667\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt_id\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtensor_dict\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt_id\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflat_input_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    668\u001b[0m                     \u001b[1;32mcontinue\u001b[0m  \u001b[1;31m# Node is not computable, try skipping.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    669\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m                 \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 671\u001b[1;33m                 \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    672\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    673\u001b[0m                 \u001b[1;31m# Update tensor_dict.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m                 for x_id, y in zip(\n",
      "\u001b[1;32mc:\\Users\\Piss Off\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tf_keras\\src\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Piss Off\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tf_keras\\src\\engine\\base_layer.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1149\u001b[0m                     )\n\u001b[0;32m   1150\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_saved_model_inputs_spec\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_save_spec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1153\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Piss Off\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tf_keras\\src\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    154\u001b[0m                 \u001b[0mnew_e\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mnew_e\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0msignature\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m             \u001b[1;32mdel\u001b[0m \u001b[0mbound_signature\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Piss Off\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tf_keras\\src\\layers\\convolutional\\base_conv.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    285\u001b[0m             outputs = self._jit_compiled_convolution_op(\n\u001b[0;32m    286\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m             )\n\u001b[0;32m    288\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 289\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvolution_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m             \u001b[0moutput_rank\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Piss Off\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tf_keras\\src\\layers\\convolutional\\base_conv.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, inputs, kernel)\u001b[0m\n\u001b[0;32m    257\u001b[0m             \u001b[0mtf_padding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m             \u001b[0mtf_padding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 261\u001b[1;33m         return tf.nn.convolution(\n\u001b[0m\u001b[0;32m    262\u001b[0m             \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m             \u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m             \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrides\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Piss Off\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Piss Off\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1264\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_dispatch_handler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1265\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mOpDispatcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNOT_SUPPORTED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1266\u001b[0m           \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1267\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1268\u001b[1;33m           \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Piss Off\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(input, filters, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[0;32m   1182\u001b[0m     \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"VALID\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1183\u001b[0m     \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1184\u001b[0m     \u001b[0mdilations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m     name=None):\n\u001b[1;32m-> 1186\u001b[1;33m   return convolution_internal(\n\u001b[0m\u001b[0;32m   1187\u001b[0m       \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# pylint: disable=redefined-builtin\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1188\u001b[0m       \u001b[0mfilters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1189\u001b[0m       \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Piss Off\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(input, filters, strides, padding, data_format, dilations, name, call_from_convolution, num_spatial_dims)\u001b[0m\n\u001b[0;32m   1340\u001b[0m           \u001b[0mdilation_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1341\u001b[0m           \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1342\u001b[0m           \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1343\u001b[0m           num_spatial_dims=num_spatial_dims)\n\u001b[1;32m-> 1344\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Piss Off\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(input, filters, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[0;32m   2789\u001b[0m   \u001b[0minput_rank\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2790\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0minput_rank\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0minput_rank\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2791\u001b[0m     \u001b[1;31m# We avoid calling squeeze_batch_dims to reduce extra python function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2792\u001b[0m     \u001b[1;31m# call slowdown in eager mode.  This branch doesn't require reshapes.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2793\u001b[1;33m     return gen_nn_ops.conv2d(\n\u001b[0m\u001b[0;32m   2794\u001b[0m         \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2795\u001b[0m         \u001b[0mfilter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2796\u001b[0m         \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Piss Off\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[0;32m   1339\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1340\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1341\u001b[0m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1342\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1343\u001b[1;33m       \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1344\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1345\u001b[0m       return conv2d_eager_fallback(\n\u001b[0;32m   1346\u001b[0m           \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 🔁 Updated Loop: Recognize or Register by Comparing Faces\n",
    "known_faces_dir = \"known_faces\"\n",
    "ensure_dir(known_faces_dir)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"🚫 Failed to capture frame from webcam.\")\n",
    "        break\n",
    "\n",
    "    try:\n",
    "        # Analyze the frame for emotions\n",
    "        results = DeepFace.analyze(frame, actions=['emotion'], enforce_detection=False)\n",
    "        display_deepface_results(results)  # Call the function to display results\n",
    "\n",
    "        # Extract dominant emotion and region\n",
    "        dominant_emotion = results[0].get('dominant_emotion', 'Unknown')\n",
    "        region = results[0].get('region', {})\n",
    "\n",
    "        # Crop the face safely\n",
    "        x, y, w, h = region.get('x', 0), region.get('y', 0), region.get('w', 0), region.get('h', 0)\n",
    "        if w > 0 and h > 0:  # Ensure valid dimensions\n",
    "            face_img = frame[y:y+h, x:x+w]\n",
    "        else:\n",
    "            print(\"🚫 No face detected in the frame.\")\n",
    "            continue\n",
    "\n",
    "        matched_id = None\n",
    "\n",
    "        # Search in known faces\n",
    "        for file in os.listdir(known_faces_dir):\n",
    "            known_face_path = os.path.join(known_faces_dir, file)\n",
    "            try:\n",
    "                verified = DeepFace.verify(face_img, known_face_path, enforce_detection=False)\n",
    "                if verified.get(\"verified\"):\n",
    "                    matched_id = file.split(\"_\")[0]\n",
    "                    break\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Error verifying face with {file}: {e}\")\n",
    "                continue\n",
    "\n",
    "        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")  # Save timestamp in a readable format\n",
    "\n",
    "        if matched_id:\n",
    "            # Existing user\n",
    "            user_id = int(matched_id)\n",
    "            print(f\"✅ Recognized User ID = {user_id}\")\n",
    "        else:\n",
    "            # New user\n",
    "            user_face_id = str(int(datetime.now().timestamp()))\n",
    "            face_filename = f\"{user_face_id}_{timestamp.replace(':', '-')}.jpg\"\n",
    "            face_path = os.path.join(known_faces_dir, face_filename)\n",
    "            cv2.imwrite(face_path, face_img)\n",
    "            user_id = insert_user(user_face_id, face_path)\n",
    "            print(f\"🆕 New user added: ID = {user_id}\")\n",
    "\n",
    "        # Save visit snapshot and log\n",
    "        full_frame_path = f\"captured_faces/user_{user_id}_{timestamp.replace(':', '-')}.jpg\"\n",
    "        cv2.imwrite(full_frame_path, frame)\n",
    "        log_visit(user_id, dominant_emotion)\n",
    "\n",
    "        # Save additional details to the database\n",
    "        try:\n",
    "            cursor.execute(\n",
    "                \"INSERT INTO visit_details (user_id, timestamp, emotion, image_path) VALUES (%s, %s, %s, %s)\",\n",
    "                (user_id, timestamp, dominant_emotion, full_frame_path)\n",
    "            )\n",
    "            db.commit()\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Database error: {e}\")\n",
    "\n",
    "        # Display info on the camera feed\n",
    "        cv2.putText(frame, f\"User ID: {user_id}\", (50, 50),  # Display User ID\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        cv2.putText(frame, f\"Emotion: {dominant_emotion}\", (50, 100),  # Display Dominant Emotion\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"🚫 Face not detected or error:\", e)\n",
    "\n",
    "    cv2.imshow(\"Face Recognition & Emotion Detection\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"📷 Webcam Released & Window Closed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
