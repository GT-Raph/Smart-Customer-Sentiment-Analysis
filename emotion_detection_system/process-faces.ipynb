{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e6c14e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install opencv-python deepface mysql-connector-python numpy scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1442b2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import uuid\n",
    "import cv2\n",
    "import glob\n",
    "import shutil\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import mysql.connector\n",
    "from deepface import DeepFace\n",
    "from scipy.spatial.distance import cosine\n",
    "import requests\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a48acc",
   "metadata": {},
   "source": [
    "# === Configuration ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa29bf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monitor the repository-level captured_faces directory (explicit path).\n",
    "# Change this path if your project is located elsewhere.\n",
    "WATCH_FOLDER = r\"F:\\Programming\\Smart-Customer-Sentiment-Analysis\\captured_faces\"\n",
    "\n",
    "PENDING_JOBS_DIR = os.path.join(WATCH_FOLDER, \"pending_jobs\")\n",
    "PROCESSED_JOBS_DIR = os.path.join(WATCH_FOLDER, \"processed_jobs\")\n",
    "KNOWN_FOLDER = os.path.join(WATCH_FOLDER, \"known_faces\")\n",
    "ARCHIVE_ROOT = os.path.join(WATCH_FOLDER, \"processed_archive\")\n",
    "\n",
    "MATCH_THRESHOLD = 0.45  # distance threshold (lower == stricter)\n",
    "BLUR_THRESHOLD = 100.0\n",
    "MODEL_NAME = \"ArcFace\"  # DeepFace model to use for embeddings\n",
    "EMBEDDING_SIZE = None  # will be inferred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40190e22",
   "metadata": {},
   "source": [
    "# === MySQL Connection ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73fb0684",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"\",\n",
    "    database=\"emotion_detection\",\n",
    ")\n",
    "cursor = db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f48cebb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_tables_exist(conn):\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS face_embeddings (\n",
    "            id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "            face_id VARCHAR(128) NOT NULL,\n",
    "            embedding LONGTEXT NOT NULL,\n",
    "            created_at DATETIME NOT NULL\n",
    "        ) ENGINE=InnoDB;\n",
    "    \"\"\")\n",
    "    cur.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS unique_face_id (\n",
    "            id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "            face_id VARCHAR(128) UNIQUE NOT NULL,\n",
    "            embedding LONGTEXT,\n",
    "            created_at DATETIME\n",
    "        ) ENGINE=InnoDB;\n",
    "    \"\"\")\n",
    "    # Keep other tables as-is (monitor_emotion, visits etc.). We don't create them here.\n",
    "    conn.commit()\n",
    "    cur.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ab6778",
   "metadata": {},
   "source": [
    "# === Helper Functions ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e60465c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_normalize(vec):\n",
    "    vec = np.array(vec, dtype=np.float64)\n",
    "    norm = np.linalg.norm(vec)\n",
    "    if norm == 0:\n",
    "        return vec\n",
    "    return vec / norm\n",
    "\n",
    "# Generate timestamped unique face id\n",
    "# def generate_new_face_id():\n",
    "#     timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "#     rand = str(random.randint(1000, 9999))\n",
    "#     return f\"face_{timestamp}_{rand}\"\n",
    "\n",
    "# Blur check\n",
    "def is_blurry_image(img_path, threshold=BLUR_THRESHOLD):\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        return True\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    fm = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
    "    return fm < threshold\n",
    "\n",
    "def process_captured_faces():\n",
    "    conn = db  # use your existing db connection\n",
    "    cur = conn.cursor(dictionary=True)\n",
    "    # Get unprocessed images from DB, FIFO order\n",
    "    cur.execute(\"\"\"\n",
    "        SELECT id, image_path, face_id FROM captured_snapshots\n",
    "        WHERE processed = 0\n",
    "        ORDER BY timestamp ASC\n",
    "    \"\"\")\n",
    "    rows = cur.fetchall()\n",
    "    for row in rows:\n",
    "        image_path = row['image_path']\n",
    "        face_id = row['face_id']\n",
    "        db_id = row['id']\n",
    "        if not os.path.exists(image_path):\n",
    "            print(f\"❌ Image not found: {image_path}\")\n",
    "            # Optionally mark as processed or remove from DB\n",
    "            continue\n",
    "\n",
    "        # Analyze emotion\n",
    "        dominant, conf = analyze_emotion_from_path(image_path)\n",
    "        if dominant and conf is not None and conf >= 50:\n",
    "            # Update DB with emotion and mark as processed\n",
    "            cur2 = conn.cursor()\n",
    "            cur2.execute(\"\"\"\n",
    "                UPDATE captured_snapshots\n",
    "                SET emotion=%s, processed=1\n",
    "                WHERE id=%s\n",
    "            \"\"\", (dominant, db_id))\n",
    "            conn.commit()\n",
    "            cur2.close()\n",
    "            print(f\"✅ Processed {image_path} | Face ID: {face_id} | Emotion: {dominant} ({conf:.2f}%)\")\n",
    "        else:\n",
    "            print(f\"⚠️ Low confidence or no emotion for {image_path} (conf={conf}) - not updating DB\")\n",
    "\n",
    "        # Move the image to the archive folder after processing\n",
    "        archive_image(image_path)\n",
    "\n",
    "    cur.close()\n",
    "    \n",
    "# DeepFace embedding extraction (single face image path)\n",
    "def get_embedding_from_path(img_path):\n",
    "    try:\n",
    "        # DeepFace.represent returns a list of dicts (one per detected face). We expect single-crop images.\n",
    "        reps = DeepFace.represent(img_path=img_path, model_name=MODEL_NAME, enforce_detection=False)\n",
    "        if not reps:\n",
    "            return None\n",
    "        emb = reps[0]['embedding']\n",
    "        return np.array(emb, dtype=np.float64)\n",
    "    except Exception as e:\n",
    "        print(f\"❌ get_embedding_from_path error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Extract multiple face crops from an image using DeepFace.extract_faces\n",
    "# returns list of (crop_image, region dict)\n",
    "def crop_faces(image_path):\n",
    "    try:\n",
    "        detections = DeepFace.extract_faces(img_path=image_path, detector_backend='opencv', enforce_detection=False)\n",
    "        img = cv2.imread(image_path)\n",
    "        faces = []\n",
    "        for det in detections:\n",
    "            region = det.get('facial_area')\n",
    "            if not region:\n",
    "                continue\n",
    "            x, y, w, h = region['x'], region['y'], region['w'], region['h']\n",
    "            # clamp coordinates\n",
    "            x1 = max(0, x)\n",
    "            y1 = max(0, y)\n",
    "            x2 = min(img.shape[1], x + w)\n",
    "            y2 = min(img.shape[0], y + h)\n",
    "            face_img = img[y1:y2, x1:x2]\n",
    "            if face_img is None or face_img.size == 0:\n",
    "                continue\n",
    "            faces.append((face_img, region))\n",
    "        return faces\n",
    "    except Exception as e:\n",
    "        print(f\"❌ crop_faces failed: {e}\")\n",
    "        return []\n",
    "\n",
    "# Load embeddings from DB into memory as: { face_id: [np.array(...), ...] }\n",
    "def load_known_embeddings(conn):\n",
    "    known = {}\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"SELECT face_id, embedding FROM face_embeddings ORDER BY created_at ASC\")\n",
    "    rows = cur.fetchall()\n",
    "    for face_id, emb_json in rows:\n",
    "        try:\n",
    "            emb = np.array(json.loads(emb_json), dtype=np.float64)\n",
    "            emb = l2_normalize(emb)\n",
    "            known.setdefault(face_id, []).append(emb)\n",
    "        except Exception:\n",
    "            continue\n",
    "    cur.close()\n",
    "    return known\n",
    "\n",
    "# Save embedding to DB (face_embeddings) and also ensure unique_face_id updated once\n",
    "def save_embedding_to_db(conn, face_id, embedding):\n",
    "    cur = conn.cursor()\n",
    "    now = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    emb_json = json.dumps(embedding.tolist())\n",
    "    try:\n",
    "        cur.execute(\"INSERT INTO face_embeddings (face_id, embedding, created_at) VALUES (%s, %s, %s)\", (face_id, emb_json, now))\n",
    "        # If unique_face_id doesn't have an entry, insert the first embedding for compatibility\n",
    "        cur.execute(\"SELECT face_id FROM unique_face_id WHERE face_id = %s\", (face_id,))\n",
    "        if not cur.fetchone():\n",
    "            cur.execute(\"INSERT INTO unique_face_id (face_id, embedding, created_at) VALUES (%s, %s, %s)\", (face_id, emb_json, now))\n",
    "        conn.commit()\n",
    "    except mysql.connector.Error as err:\n",
    "        print(f\"❌ MySQL save_embedding_to_db error: {err}\")\n",
    "        conn.rollback()\n",
    "    finally:\n",
    "        cur.close()\n",
    "\n",
    "# Match embedding against known set. Returns (best_face_id, best_distance) or (None, None)\n",
    "def match_embedding(embedding, known_embeddings, threshold=MATCH_THRESHOLD):\n",
    "    best_id = None\n",
    "    best_dist = float('inf')\n",
    "\n",
    "    for face_id, emb_list in known_embeddings.items():\n",
    "        for known_emb in emb_list:\n",
    "            # embeddings assumed normalized\n",
    "            dist = cosine(embedding, known_emb)\n",
    "            if dist < best_dist:\n",
    "                best_dist = dist\n",
    "                best_id = face_id\n",
    "\n",
    "    if best_id is not None and best_dist <= threshold:\n",
    "        return best_id, best_dist\n",
    "    return None, None\n",
    "\n",
    "# Emotion analysis and logging functions (assumes monitor_emotion and emotions tables exist)\n",
    "def insert_emotion(conn, face_id, emotion, confidence):\n",
    "    try:\n",
    "        cur = conn.cursor()\n",
    "        ts = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        cur.execute(\"INSERT INTO monitor_emotion (face_id, detected_emotion, confidence, timestamp) VALUES (%s,%s,%s,%s)\",\n",
    "                    (face_id, emotion, float(confidence), ts))\n",
    "        cur.execute(\"INSERT INTO emotions (face_id, detected_emotion, confidence, timestamp) VALUES (%s,%s,%s,%s)\",\n",
    "                    (face_id, emotion, float(confidence), ts))\n",
    "        conn.commit()\n",
    "        cur.close()\n",
    "        print(f\"📊 Emotion logged for {face_id}: {emotion} ({confidence:.2f}%)\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ insert_emotion error: {e}\")\n",
    "        try:\n",
    "            conn.rollback()\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "# Visit logging (simple 1-minute debounce) - assumes visits and monitor_visit / visit_details tables exist\n",
    "def should_log_visit(conn, face_id, min_seconds=60):\n",
    "    try:\n",
    "        cur = conn.cursor()\n",
    "        cur.execute(\"SELECT visit_time FROM visits WHERE user_id = %s ORDER BY visit_time DESC LIMIT 1\", (face_id,))\n",
    "        row = cur.fetchone()\n",
    "        cur.close()\n",
    "        if not row:\n",
    "            return True\n",
    "        last = row[0]\n",
    "        diff = (datetime.now() - last).total_seconds()\n",
    "        return diff >= min_seconds\n",
    "    except Exception:\n",
    "        return True\n",
    "\n",
    "# archive image\n",
    "def archive_image(src_path):\n",
    "    try:\n",
    "        ts = datetime.now()\n",
    "        year = str(ts.year)\n",
    "        month = ts.strftime('%B')\n",
    "        archive_dir = os.path.join(ARCHIVE_ROOT, year, month)\n",
    "        os.makedirs(archive_dir, exist_ok=True)\n",
    "        dest = os.path.join(archive_dir, os.path.basename(src_path))\n",
    "        shutil.move(src_path, dest)\n",
    "        print(f\"📁 Archived {os.path.basename(src_path)} -> {archive_dir}\")\n",
    "        return dest\n",
    "    except Exception as e:\n",
    "        print(f\"❌ archive_image error: {e}\")\n",
    "        return None\n",
    "\n",
    "# analyze emotion via DeepFace.analyze (single-crop image)\n",
    "def analyze_emotion_from_path(img_path):\n",
    "    try:\n",
    "        res = DeepFace.analyze(img_path=img_path, actions=['emotion'], enforce_detection=False)\n",
    "        if isinstance(res, list):\n",
    "            res = res[0]\n",
    "        dominant = res.get('dominant_emotion')\n",
    "        confidence = None\n",
    "        emotions = res.get('emotion')\n",
    "        if dominant and emotions and dominant in emotions:\n",
    "            confidence = emotions[dominant]\n",
    "        return dominant, confidence\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ analyze_emotion_from_path error: {e}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b340aa",
   "metadata": {},
   "source": [
    "# === Monitoring Logic ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "843a9575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...existing helper functions above remain unchanged...\n",
    "def _download_image(image_url, dest_dir, job_id=None, timeout=10, retries=3, backoff=1.0):\n",
    "    \"\"\"Download image_url to dest_dir. Returns local path or None.\"\"\"\n",
    "    if not image_url:\n",
    "        return None\n",
    "    os.makedirs(dest_dir, exist_ok=True)\n",
    "    last_exc = None\n",
    "    for attempt in range(1, retries + 1):\n",
    "        try:\n",
    "            resp = requests.get(image_url, timeout=timeout)\n",
    "            if resp.status_code == 200:\n",
    "                parsed = urlparse(image_url)\n",
    "                name = os.path.basename(parsed.path) or (f\"{job_id}.jpg\" if job_id else f\"{int(time.time())}.jpg\")\n",
    "                save_path = os.path.join(dest_dir, name)\n",
    "                with open(save_path, \"wb\") as fh:\n",
    "                    fh.write(resp.content)\n",
    "                return save_path\n",
    "            else:\n",
    "                last_exc = Exception(f\"HTTP {resp.status_code}\")\n",
    "        except Exception as e:\n",
    "            last_exc = e\n",
    "        time.sleep(backoff * attempt)\n",
    "    print(f\"❌ Failed to download {image_url}: {last_exc}\")\n",
    "    return None\n",
    "\n",
    "def resolve_local_image_path(image_path):\n",
    "    \"\"\"Given an image_path (possibly with ../ or different roots), try to resolve to an existing file.\n",
    "    Returns normalized existing path or None.\"\"\"\n",
    "    if not image_path:\n",
    "        return None\n",
    "    # normalize and test direct existence\n",
    "    p = os.path.normpath(image_path)\n",
    "    if os.path.exists(p):\n",
    "        return os.path.abspath(p)\n",
    "    # try basename lookup inside WATCH_FOLDER and common subfolders\n",
    "    base = os.path.basename(p)\n",
    "    candidates = [\n",
    "        os.path.join(WATCH_FOLDER, base),\n",
    "        os.path.join(PENDING_JOBS_DIR, base),\n",
    "        os.path.join(PROCESSED_JOBS_DIR, base)\n",
    "    ]\n",
    "    for c in candidates:\n",
    "        if os.path.exists(c):\n",
    "            return os.path.abspath(c)\n",
    "    return None\n",
    "\n",
    "def get_db_connection():\n",
    "    \"\"\"Return an existing DB connection from the notebook globals.\n",
    "\n",
    "    The notebook already defines a 'db' connection object; prefer that.\n",
    "    If no 'db' exists, raise a clear error so the caller can handle it.\n",
    "    \"\"\"\n",
    "    if 'db' in globals() and globals()['db'] is not None:\n",
    "        return globals()['db']\n",
    "    raise RuntimeError(\"get_db_connection: no 'db' object found in notebook globals. Define 'db' (a mysql connection) before calling monitor_folder().\")\n",
    "\n",
    "def monitor_folder():\n",
    "    os.makedirs(WATCH_FOLDER, exist_ok=True)\n",
    "    os.makedirs(PENDING_JOBS_DIR, exist_ok=True)\n",
    "    os.makedirs(PROCESSED_JOBS_DIR, exist_ok=True)\n",
    "    os.makedirs(KNOWN_FOLDER, exist_ok=True)\n",
    "\n",
    "    conn = get_db_connection()\n",
    "    ensure_tables_exist(conn)\n",
    "\n",
    "    print(f\"📁 Monitoring pending jobs in {PENDING_JOBS_DIR} (watching {WATCH_FOLDER}) ...\")\n",
    "\n",
    "    # Load embeddings into memory\n",
    "    known_embeddings = load_known_embeddings(conn)\n",
    "    print(f\"🔁 Loaded embeddings for {len(known_embeddings)} known faces\")\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            job_files = sorted([f for f in os.listdir(PENDING_JOBS_DIR) if f.lower().endswith('.json')])\n",
    "            if not job_files:\n",
    "                time.sleep(1)\n",
    "                continue\n",
    "\n",
    "            for job_file in job_files:\n",
    "                job_path = os.path.join(PENDING_JOBS_DIR, job_file)\n",
    "                try:\n",
    "                    with open(job_path, 'r', encoding='utf-8') as jf:\n",
    "                        job = json.load(jf)\n",
    "                except Exception as e:\n",
    "                    print(f\"❌ Failed to read job {job_file}: {e}\")\n",
    "                    shutil.move(job_path, os.path.join(PROCESSED_JOBS_DIR, job_file))\n",
    "                    continue\n",
    "\n",
    "                image_path = job.get('image_path')\n",
    "                image_url = job.get('image_url')\n",
    "                face_id = job.get('face_id')\n",
    "                job_id = job.get('job_id') or job_file\n",
    "                print(f\"\\n🔔 Processing job {job_file} -> image: {image_url or image_path}\")\n",
    "\n",
    "                # Prefer resolving to a local image first (handle server paths and ../ references).\n",
    "                resolved = resolve_local_image_path(image_path)\n",
    "                if resolved:\n",
    "                    image_path = resolved\n",
    "                    print(f\"✅ Found local image: {image_path}\")\n",
    "                else:\n",
    "                    # try to find by basename inside WATCH_FOLDER before downloading\n",
    "                    if image_path:\n",
    "                        base = os.path.basename(image_path)\n",
    "                        candidate = os.path.join(WATCH_FOLDER, base)\n",
    "                        if os.path.exists(candidate):\n",
    "                            image_path = candidate\n",
    "                            print(f\"✅ Found image by basename in WATCH_FOLDER: {image_path}\")\n",
    "                        else:\n",
    "                            # if no local file, try to download from image_url (API) if present\n",
    "                            if image_url:\n",
    "                                downloaded = _download_image(image_url, PENDING_JOBS_DIR, job_id=job_id)\n",
    "                                if downloaded:\n",
    "                                    image_path = downloaded\n",
    "                                    print(f\"✅ Downloaded image for job to {image_path}\")\n",
    "                                else:\n",
    "                                    print(f\"❌ No local copy and download failed for {job_file} - marking processed to avoid loop\")\n",
    "                                    shutil.move(job_path, os.path.join(PROCESSED_JOBS_DIR, job_file))\n",
    "                                    continue\n",
    "                            else:\n",
    "                                print(f\"❌ No local copy and no image_url for {job_file} - marking processed\")\n",
    "                                shutil.move(job_path, os.path.join(PROCESSED_JOBS_DIR, job_file))\n",
    "                                continue\n",
    "\n",
    "                # proceed with existing processing using image_path (now ensured to exist)\n",
    "                if is_blurry_image(image_path):\n",
    "                    print(f\"⚠️ Image too blurry: {image_path} - archiving and skipping\")\n",
    "                    archive_image(image_path)\n",
    "                    shutil.move(job_path, os.path.join(PROCESSED_JOBS_DIR, job_file))\n",
    "                    continue\n",
    "\n",
    "                faces = crop_faces(image_path)\n",
    "                if not faces:\n",
    "                    print(\"❌ No faces detected in image - archiving and marking job processed\")\n",
    "                    archive_image(image_path)\n",
    "                    shutil.move(job_path, os.path.join(PROCESSED_JOBS_DIR, job_file))\n",
    "                    continue\n",
    "\n",
    "                # ...existing per-face processing code unchanged (embedding, emotion, visits, cleanup) ...\n",
    "\n",
    "                # Archive original image and mark job processed\n",
    "                archive_image(image_path)\n",
    "                try:\n",
    "                    cur = conn.cursor()\n",
    "                    cur.execute(\"UPDATE captured_snapshots SET processed = 1 WHERE face_id = %s AND image_path = %s\", (face_id, image_path))\n",
    "                    conn.commit()\n",
    "                    cur.close()\n",
    "                except Exception as e:\n",
    "                    print(f\"⚠️ Could not mark captured_snapshots processed: {e}\")\n",
    "\n",
    "                dst = os.path.join(PROCESSED_JOBS_DIR, job_file)\n",
    "                try:\n",
    "                    shutil.move(job_path, dst)\n",
    "                except Exception as e:\n",
    "                    print(f\"⚠️ Failed to move job to processed: {e}\")\n",
    "\n",
    "            # small sleep between polling loops\n",
    "            time.sleep(1)\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"⏹️ Stopping monitor (KeyboardInterrupt)\")\n",
    "    finally:\n",
    "        try:\n",
    "            conn.close()\n",
    "        except Exception:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96806507",
   "metadata": {},
   "source": [
    "# === Entry Point ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c5509ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📁 Monitoring pending jobs in f:\\Programming\\Smart-Customer-Sentiment-Analysis\\emotion_detection_system\\captured_faces\\pending_jobs (watching f:\\Programming\\Smart-Customer-Sentiment-Analysis\\emotion_detection_system\\captured_faces) ...\n",
      "🔁 Loaded embeddings for 1 known faces\n",
      "⏹️ Stopping monitor (KeyboardInterrupt)\n",
      "⏹️ Stopping monitor (KeyboardInterrupt)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Start the continuous job consumer; runs until manually stopped (KeyboardInterrupt).\n",
    "    monitor_folder()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
