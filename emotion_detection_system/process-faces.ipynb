{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e6c14e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install opencv-python deepface mysql-connector-python numpy scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1442b2ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Piss Off\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import uuid\n",
    "import cv2\n",
    "import glob\n",
    "import shutil\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import mysql.connector\n",
    "from deepface import DeepFace\n",
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a48acc",
   "metadata": {},
   "source": [
    "# === Configuration ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa29bf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "WATCH_FOLDER = \"captured_faces\"\n",
    "KNOWN_FOLDER = \"known_faces\"\n",
    "ARCHIVE_ROOT = \"Process\"\n",
    "MATCH_THRESHOLD = 0.45  # distance threshold (lower == stricter)\n",
    "BLUR_THRESHOLD = 100.0\n",
    "MODEL_NAME = \"ArcFace\"  # DeepFace model to use for embeddings\n",
    "EMBEDDING_SIZE = None  # will be inferred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40190e22",
   "metadata": {},
   "source": [
    "# === MySQL Connection ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73fb0684",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"\",\n",
    "    database=\"emotion_detection\"\n",
    ")\n",
    "cursor = db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f48cebb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_tables_exist(conn):\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS face_embeddings (\n",
    "            id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "            face_id VARCHAR(128) NOT NULL,\n",
    "            embedding LONGTEXT NOT NULL,\n",
    "            created_at DATETIME NOT NULL\n",
    "        ) ENGINE=InnoDB;\n",
    "    \"\"\")\n",
    "    cur.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS unique_face_id (\n",
    "            id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "            face_id VARCHAR(128) UNIQUE NOT NULL,\n",
    "            embedding LONGTEXT,\n",
    "            created_at DATETIME\n",
    "        ) ENGINE=InnoDB;\n",
    "    \"\"\")\n",
    "    # Keep other tables as-is (monitor_emotion, visits etc.). We don't create them here.\n",
    "    conn.commit()\n",
    "    cur.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ab6778",
   "metadata": {},
   "source": [
    "# === Helper Functions ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e60465c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_normalize(vec):\n",
    "    vec = np.array(vec, dtype=np.float64)\n",
    "    norm = np.linalg.norm(vec)\n",
    "    if norm == 0:\n",
    "        return vec\n",
    "    return vec / norm\n",
    "\n",
    "# Generate timestamped unique face id\n",
    "# def generate_new_face_id():\n",
    "#     timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "#     rand = str(random.randint(1000, 9999))\n",
    "#     return f\"face_{timestamp}_{rand}\"\n",
    "\n",
    "# Blur check\n",
    "def is_blurry_image(img_path, threshold=BLUR_THRESHOLD):\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        return True\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    fm = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
    "    return fm < threshold\n",
    "\n",
    "def process_captured_faces():\n",
    "    conn = db  # use your existing db connection\n",
    "    cur = conn.cursor(dictionary=True)\n",
    "    # Get unprocessed images from DB, FIFO order\n",
    "    cur.execute(\"\"\"\n",
    "        SELECT id, image_path, face_id FROM captured_snapshots\n",
    "        WHERE processed = 0\n",
    "        ORDER BY timestamp ASC\n",
    "    \"\"\")\n",
    "    rows = cur.fetchall()\n",
    "    for row in rows:\n",
    "        image_path = row['image_path']\n",
    "        face_id = row['face_id']\n",
    "        db_id = row['id']\n",
    "        if not os.path.exists(image_path):\n",
    "            print(f\"❌ Image not found: {image_path}\")\n",
    "            # Optionally mark as processed or remove from DB\n",
    "            continue\n",
    "\n",
    "        # Analyze emotion\n",
    "        dominant, conf = analyze_emotion_from_path(image_path)\n",
    "        if dominant and conf is not None and conf >= 50:\n",
    "            # Update DB with emotion and mark as processed\n",
    "            cur2 = conn.cursor()\n",
    "            cur2.execute(\"\"\"\n",
    "                UPDATE captured_snapshots\n",
    "                SET emotion=%s, processed=1\n",
    "                WHERE id=%s\n",
    "            \"\"\", (dominant, db_id))\n",
    "            conn.commit()\n",
    "            cur2.close()\n",
    "            print(f\"✅ Processed {image_path} | Face ID: {face_id} | Emotion: {dominant} ({conf:.2f}%)\")\n",
    "        else:\n",
    "            print(f\"⚠️ Low confidence or no emotion for {image_path} (conf={conf}) - not updating DB\")\n",
    "\n",
    "        # Move the image to the archive folder after processing\n",
    "        archive_image(image_path)\n",
    "\n",
    "    cur.close()\n",
    "    \n",
    "# DeepFace embedding extraction (single face image path)\n",
    "def get_embedding_from_path(img_path):\n",
    "    try:\n",
    "        # DeepFace.represent returns a list of dicts (one per detected face). We expect single-crop images.\n",
    "        reps = DeepFace.represent(img_path=img_path, model_name=MODEL_NAME, enforce_detection=False)\n",
    "        if not reps:\n",
    "            return None\n",
    "        emb = reps[0]['embedding']\n",
    "        return np.array(emb, dtype=np.float64)\n",
    "    except Exception as e:\n",
    "        print(f\"❌ get_embedding_from_path error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Extract multiple face crops from an image using DeepFace.extract_faces\n",
    "# returns list of (crop_image, region dict)\n",
    "def crop_faces(image_path):\n",
    "    try:\n",
    "        detections = DeepFace.extract_faces(img_path=image_path, detector_backend='opencv', enforce_detection=False)\n",
    "        img = cv2.imread(image_path)\n",
    "        faces = []\n",
    "        for det in detections:\n",
    "            region = det.get('facial_area')\n",
    "            if not region:\n",
    "                continue\n",
    "            x, y, w, h = region['x'], region['y'], region['w'], region['h']\n",
    "            # clamp coordinates\n",
    "            x1 = max(0, x)\n",
    "            y1 = max(0, y)\n",
    "            x2 = min(img.shape[1], x + w)\n",
    "            y2 = min(img.shape[0], y + h)\n",
    "            face_img = img[y1:y2, x1:x2]\n",
    "            if face_img is None or face_img.size == 0:\n",
    "                continue\n",
    "            faces.append((face_img, region))\n",
    "        return faces\n",
    "    except Exception as e:\n",
    "        print(f\"❌ crop_faces failed: {e}\")\n",
    "        return []\n",
    "\n",
    "# Load embeddings from DB into memory as: { face_id: [np.array(...), ...] }\n",
    "def load_known_embeddings(conn):\n",
    "    known = {}\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"SELECT face_id, embedding FROM face_embeddings ORDER BY created_at ASC\")\n",
    "    rows = cur.fetchall()\n",
    "    for face_id, emb_json in rows:\n",
    "        try:\n",
    "            emb = np.array(json.loads(emb_json), dtype=np.float64)\n",
    "            emb = l2_normalize(emb)\n",
    "            known.setdefault(face_id, []).append(emb)\n",
    "        except Exception:\n",
    "            continue\n",
    "    cur.close()\n",
    "    return known\n",
    "\n",
    "# Save embedding to DB (face_embeddings) and also ensure unique_face_id updated once\n",
    "def save_embedding_to_db(conn, face_id, embedding):\n",
    "    cur = conn.cursor()\n",
    "    now = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    emb_json = json.dumps(embedding.tolist())\n",
    "    try:\n",
    "        cur.execute(\"INSERT INTO face_embeddings (face_id, embedding, created_at) VALUES (%s, %s, %s)\", (face_id, emb_json, now))\n",
    "        # If unique_face_id doesn't have an entry, insert the first embedding for compatibility\n",
    "        cur.execute(\"SELECT face_id FROM unique_face_id WHERE face_id = %s\", (face_id,))\n",
    "        if not cur.fetchone():\n",
    "            cur.execute(\"INSERT INTO unique_face_id (face_id, embedding, created_at) VALUES (%s, %s, %s)\", (face_id, emb_json, now))\n",
    "        conn.commit()\n",
    "    except mysql.connector.Error as err:\n",
    "        print(f\"❌ MySQL save_embedding_to_db error: {err}\")\n",
    "        conn.rollback()\n",
    "    finally:\n",
    "        cur.close()\n",
    "\n",
    "# Match embedding against known set. Returns (best_face_id, best_distance) or (None, None)\n",
    "def match_embedding(embedding, known_embeddings, threshold=MATCH_THRESHOLD):\n",
    "    best_id = None\n",
    "    best_dist = float('inf')\n",
    "\n",
    "    for face_id, emb_list in known_embeddings.items():\n",
    "        for known_emb in emb_list:\n",
    "            # embeddings assumed normalized\n",
    "            dist = cosine(embedding, known_emb)\n",
    "            if dist < best_dist:\n",
    "                best_dist = dist\n",
    "                best_id = face_id\n",
    "\n",
    "    if best_id is not None and best_dist <= threshold:\n",
    "        return best_id, best_dist\n",
    "    return None, None\n",
    "\n",
    "# Emotion analysis and logging functions (assumes monitor_emotion and emotions tables exist)\n",
    "def insert_emotion(conn, face_id, emotion, confidence):\n",
    "    try:\n",
    "        cur = conn.cursor()\n",
    "        ts = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        cur.execute(\"INSERT INTO monitor_emotion (face_id, detected_emotion, confidence, timestamp) VALUES (%s,%s,%s,%s)\",\n",
    "                    (face_id, emotion, float(confidence), ts))\n",
    "        cur.execute(\"INSERT INTO emotions (face_id, detected_emotion, confidence, timestamp) VALUES (%s,%s,%s,%s)\",\n",
    "                    (face_id, emotion, float(confidence), ts))\n",
    "        conn.commit()\n",
    "        cur.close()\n",
    "        print(f\"📊 Emotion logged for {face_id}: {emotion} ({confidence:.2f}%)\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ insert_emotion error: {e}\")\n",
    "        try:\n",
    "            conn.rollback()\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "# Visit logging (simple 1-minute debounce) - assumes visits and monitor_visit / visit_details tables exist\n",
    "def should_log_visit(conn, face_id, min_seconds=60):\n",
    "    try:\n",
    "        cur = conn.cursor()\n",
    "        cur.execute(\"SELECT visit_time FROM visits WHERE user_id = %s ORDER BY visit_time DESC LIMIT 1\", (face_id,))\n",
    "        row = cur.fetchone()\n",
    "        cur.close()\n",
    "        if not row:\n",
    "            return True\n",
    "        last = row[0]\n",
    "        diff = (datetime.now() - last).total_seconds()\n",
    "        return diff >= min_seconds\n",
    "    except Exception:\n",
    "        return True\n",
    "\n",
    "# archive image\n",
    "def archive_image(src_path):\n",
    "    try:\n",
    "        ts = datetime.now()\n",
    "        year = str(ts.year)\n",
    "        month = ts.strftime('%B')\n",
    "        archive_dir = os.path.join(ARCHIVE_ROOT, year, month)\n",
    "        os.makedirs(archive_dir, exist_ok=True)\n",
    "        dest = os.path.join(archive_dir, os.path.basename(src_path))\n",
    "        shutil.move(src_path, dest)\n",
    "        print(f\"📁 Archived {os.path.basename(src_path)} -> {archive_dir}\")\n",
    "        return dest\n",
    "    except Exception as e:\n",
    "        print(f\"❌ archive_image error: {e}\")\n",
    "        return None\n",
    "\n",
    "# analyze emotion via DeepFace.analyze (single-crop image)\n",
    "def analyze_emotion_from_path(img_path):\n",
    "    try:\n",
    "        res = DeepFace.analyze(img_path=img_path, actions=['emotion'], enforce_detection=False)\n",
    "        if isinstance(res, list):\n",
    "            res = res[0]\n",
    "        dominant = res.get('dominant_emotion')\n",
    "        confidence = None\n",
    "        emotions = res.get('emotion')\n",
    "        if dominant and emotions and dominant in emotions:\n",
    "            confidence = emotions[dominant]\n",
    "        return dominant, confidence\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ analyze_emotion_from_path error: {e}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b340aa",
   "metadata": {},
   "source": [
    "# === Monitoring Logic ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "843a9575",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_db_connection():\n",
    "    import mysql.connector\n",
    "    # Update with your actual DB credentials\n",
    "    return mysql.connector.connect(\n",
    "        host=\"localhost\",\n",
    "        user=\"root\",\n",
    "        password=\"\",\n",
    "        database=\"emotion_detection\"\n",
    "    )\n",
    "\n",
    "def monitor_folder():\n",
    "    os.makedirs(WATCH_FOLDER, exist_ok=True)\n",
    "    os.makedirs(KNOWN_FOLDER, exist_ok=True)\n",
    "\n",
    "    conn = get_db_connection()\n",
    "    ensure_tables_exist(conn)\n",
    "\n",
    "    print(f\"📁 Monitoring {WATCH_FOLDER} ...\")\n",
    "\n",
    "    # Load embeddings into memory\n",
    "    known_embeddings = load_known_embeddings(conn)\n",
    "    print(f\"🔁 Loaded embeddings for {len(known_embeddings)} known faces\")\n",
    "\n",
    "    processed = set()\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            files = [f for f in os.listdir(WATCH_FOLDER) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "            for file in files:\n",
    "                if file in processed:\n",
    "                    continue\n",
    "                path = os.path.join(WATCH_FOLDER, file)\n",
    "                print(f\"\\n🖼️ New image: {file}\")\n",
    "\n",
    "                faces = crop_faces(path)\n",
    "                if not faces:\n",
    "                    print(\"❌ No faces detected - archiving anyway\")\n",
    "                    archive_image(path)\n",
    "                    processed.add(file)\n",
    "                    continue\n",
    "\n",
    "                # process each face crop independently                \n",
    "                for i, (face_img, region) in enumerate(faces):\n",
    "                    temp_name = f\"temp_{uuid.uuid4().hex[:8]}.jpg\"\n",
    "                    cv2.imwrite(temp_name, face_img)\n",
    "\n",
    "                    emb = get_embedding_from_path(temp_name)\n",
    "                    if emb is None:\n",
    "                        print(\"⚠️ Could not extract embedding for face, skipping\")\n",
    "                        os.remove(temp_name)\n",
    "                        continue\n",
    "\n",
    "                    emb = l2_normalize(emb)\n",
    "\n",
    "                    matched_id, dist = match_embedding(emb, known_embeddings)\n",
    "\n",
    "                    if matched_id:\n",
    "                        face_id = matched_id\n",
    "                        print(f\"✅ Face matched -> {face_id} (dist={dist:.4f})\")\n",
    "                        # Optionally store this embedding to that face_id to improve robustness\n",
    "                        try:\n",
    "                            save_embedding_to_db(conn, face_id, emb)\n",
    "                            known_embeddings.setdefault(face_id, []).append(emb)\n",
    "                        except Exception:\n",
    "                            pass\n",
    "                    else:\n",
    "                        print(\"🆕 New face detected but face_id assignment should be handled at capture stage. Skipping new face_id generation.\")\n",
    "                        # Optionally: skip saving or handle as needed for your workflow\n",
    "\n",
    "                    # Emotion analysis\n",
    "                    dominant, conf = analyze_emotion_from_path(temp_name)\n",
    "                    if dominant and conf is not None and conf >= 50:\n",
    "                        insert_emotion(conn, face_id, dominant, conf)\n",
    "                    else:\n",
    "                        print(f\"⚠️ Emotion low-confidence or missing ({conf}) - skipped logging\")\n",
    "\n",
    "                    # Visit logging (very simple)\n",
    "                    try:\n",
    "                        if should_log_visit(conn, face_id):\n",
    "                            cur = conn.cursor()\n",
    "                            ts = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "                            cur.execute(\"INSERT INTO visits (user_id, emotion, visit_time) VALUES (%s,%s,%s)\", (face_id, dominant or 'unknown', ts))\n",
    "                            cur.execute(\"INSERT INTO monitor_visit (face_id, visit_time) VALUES (%s,%s)\", (face_id, ts))\n",
    "                            conn.commit()\n",
    "                            cur.close()\n",
    "                            print(f\"📝 Logged visit for {face_id}\")\n",
    "                        else:\n",
    "                            print(\"⏳ Skipped visit logging (debounce)\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"❌ visit logging error: {e}\")\n",
    "\n",
    "                    # cleanup temp\n",
    "                    os.remove(temp_name)\n",
    "\n",
    "                # archive the original image after processing all faces\n",
    "                archive_image(path)\n",
    "\n",
    "                processed.add(file)\n",
    "                \n",
    "\n",
    "            time.sleep(2)\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"⏹️ Stopping monitor (KeyboardInterrupt)\")\n",
    "    finally:\n",
    "        try:\n",
    "            conn.close()\n",
    "        except Exception:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96806507",
   "metadata": {},
   "source": [
    "# === Entry Point ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c5509ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Low confidence or no emotion for captured_faces\\01K362ZWTA8RSRNX0EFJM1C5SW_20250821_103231.jpg (conf=38.450042724609375) - not updating DB\n",
      "📁 Archived 01K362ZWTA8RSRNX0EFJM1C5SW_20250821_103231.jpg -> Process\\2025\\August\n",
      "✅ Processed captured_faces\\01K362ZWTA8RSRNX0EFJM1C5SW_20250821_103247.jpg | Face ID: 01K362ZWTA8RSRNX0EFJM1C5SW | Emotion: angry (68.59%)\n",
      "📁 Archived 01K362ZWTA8RSRNX0EFJM1C5SW_20250821_103247.jpg -> Process\\2025\\August\n",
      "⚠️ Low confidence or no emotion for captured_faces\\01K362ZWTA8RSRNX0EFJM1C5SW_20250821_103249.jpg (conf=42.13692855834961) - not updating DB\n",
      "📁 Archived 01K362ZWTA8RSRNX0EFJM1C5SW_20250821_103249.jpg -> Process\\2025\\August\n",
      "✅ Processed captured_faces\\01K362ZWTA8RSRNX0EFJM1C5SW_20250821_103250.jpg | Face ID: 01K362ZWTA8RSRNX0EFJM1C5SW | Emotion: angry (60.66%)\n",
      "📁 Archived 01K362ZWTA8RSRNX0EFJM1C5SW_20250821_103250.jpg -> Process\\2025\\August\n",
      "✅ Processed captured_faces\\01K362ZWTA8RSRNX0EFJM1C5SW_20250821_103253.jpg | Face ID: 01K362ZWTA8RSRNX0EFJM1C5SW | Emotion: angry (96.70%)\n",
      "📁 Archived 01K362ZWTA8RSRNX0EFJM1C5SW_20250821_103253.jpg -> Process\\2025\\August\n",
      "✅ Processed captured_faces\\01K362ZWTA8RSRNX0EFJM1C5SW_20250821_103306.jpg | Face ID: 01K362ZWTA8RSRNX0EFJM1C5SW | Emotion: angry (51.03%)\n",
      "📁 Archived 01K362ZWTA8RSRNX0EFJM1C5SW_20250821_103306.jpg -> Process\\2025\\August\n",
      "✅ Processed captured_faces\\01K362ZWTA8RSRNX0EFJM1C5SW_20250821_103308.jpg | Face ID: 01K362ZWTA8RSRNX0EFJM1C5SW | Emotion: angry (77.19%)\n",
      "📁 Archived 01K362ZWTA8RSRNX0EFJM1C5SW_20250821_103308.jpg -> Process\\2025\\August\n",
      "⚠️ Low confidence or no emotion for captured_faces\\01K362ZWTA8RSRNX0EFJM1C5SW_20250821_103310.jpg (conf=37.23357009887695) - not updating DB\n",
      "📁 Archived 01K362ZWTA8RSRNX0EFJM1C5SW_20250821_103310.jpg -> Process\\2025\\August\n",
      "✅ Processed captured_faces\\01K362ZWTA8RSRNX0EFJM1C5SW_20250821_103311.jpg | Face ID: 01K362ZWTA8RSRNX0EFJM1C5SW | Emotion: neutral (50.27%)\n",
      "📁 Archived 01K362ZWTA8RSRNX0EFJM1C5SW_20250821_103311.jpg -> Process\\2025\\August\n",
      "✅ Processed captured_faces\\01K363NP0KDX5DXENBYSFVBS79_20250821_104425.jpg | Face ID: 01K363NP0KDX5DXENBYSFVBS79 | Emotion: neutral (99.95%)\n",
      "📁 Archived 01K363NP0KDX5DXENBYSFVBS79_20250821_104425.jpg -> Process\\2025\\August\n",
      "✅ Processed captured_faces\\01K363NP0KDX5DXENBYSFVBS79_20250821_104426.jpg | Face ID: 01K363NP0KDX5DXENBYSFVBS79 | Emotion: neutral (99.97%)\n",
      "📁 Archived 01K363NP0KDX5DXENBYSFVBS79_20250821_104426.jpg -> Process\\2025\\August\n",
      "✅ Processed captured_faces\\01K363NP0KDX5DXENBYSFVBS79_20250821_104428.jpg | Face ID: 01K363NP0KDX5DXENBYSFVBS79 | Emotion: sad (55.85%)\n",
      "📁 Archived 01K363NP0KDX5DXENBYSFVBS79_20250821_104428.jpg -> Process\\2025\\August\n",
      "✅ Processed captured_faces\\01K362ZWTA8RSRNX0EFJM1C5SW_20250821_104429.jpg | Face ID: 01K362ZWTA8RSRNX0EFJM1C5SW | Emotion: neutral (99.95%)\n",
      "📁 Archived 01K362ZWTA8RSRNX0EFJM1C5SW_20250821_104429.jpg -> Process\\2025\\August\n",
      "✅ Processed captured_faces\\01K363NP0KDX5DXENBYSFVBS79_20250821_104431.jpg | Face ID: 01K363NP0KDX5DXENBYSFVBS79 | Emotion: neutral (99.80%)\n",
      "📁 Archived 01K363NP0KDX5DXENBYSFVBS79_20250821_104431.jpg -> Process\\2025\\August\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    process_captured_faces()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
